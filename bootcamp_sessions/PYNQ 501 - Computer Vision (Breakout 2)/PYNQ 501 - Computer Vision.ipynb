{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision\n",
    "----\n",
    "\n",
    "This notebook introduces some of the image processing algorithms/functions using the OpenCV library\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Description |\n",
    "| :-: | :-: |\n",
    "| Read Image | Read an image using cv.imread |\n",
    "| plot_images | Plots two images side by side |\n",
    "| Convert RGB to grayscale | Converts an RGB image to a grascale image |\n",
    "| Convert RGB to HSV | Converts an RGB image to an HSV image |\n",
    "| Corner Detector | Uses an algorithm called Harris corner detector to detect edges and corner |\n",
    "| Normalize | Normalize the values of the image |\n",
    "| central_crop | Crops the image with the given image dimensions around the center |\n",
    "| BGR2RGB | Converts a BGR image to an RGB image |\n",
    "| resize_shortest_edge | While maintaining the aspect ratio of the image, resizes the shortest edge |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aren't we doing computer vision throughout this bootcamp? Then why have a dedicated session for computer vision?\n",
    "\n",
    "Computer Vision: Traditional method to teach computer understand images\n",
    "\n",
    "CNNs: human inspired computing paradigm for computers to understand images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV <a class=\"anchor\" id=\"opencv\"></a>\n",
    "\n",
    "[OpenCV](https://opencv.org/) is an open source cross platform computer vision library. You will be using OpenCV to get familiar with some of the computer vision functions.\n",
    "\n",
    "Import numpy, OpenCV and matplotlib to visualize images. We will use a mosaic image to demonstrate the effect of some vision operation to such image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read an image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('img/mosaic.jpg')\n",
    "plt.figure(figsize=(10, 10)), plt.axis(\"off\"), plt.imshow(img);\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to plot images next to each other?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(original_image, processed_image):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(121),plt.imshow(original_image),plt.title('Original')\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(processed_image),plt.title('Processed')\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to convert RGB image to Grayscale image?\n",
    "\n",
    "A color image is represented on the [RGB color space](https://en.wikipedia.org/wiki/RGB_color_space), however there are many different color spaces. Each of them have a particular purpose. We will explore some of them\n",
    "\n",
    "A [grayscale image](https://en.wikipedia.org/wiki/Grayscale) has only one channel which represents the amount of light that each pixel contains. One of the main purposes of grayscale images on vision applications is to detect edges on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "# plt.figure(figsize=(10, 10)), plt.axis(\"off\"), plt.imshow(gray, cmap='gray');\n",
    "plot_images(img, gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to convert RGB image to HSV format?\n",
    "\n",
    "[HSV color space](https://en.wikipedia.org/wiki/HSL_and_HSV) represents an image using the channels hue, saturation and value. This color space aligns a bit better to the way human perceives color-making attributes, and in vision application this color space is useful to detect color more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "plot_images(img, hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corner Detector  \n",
    "\n",
    "### Harris Corner Detector\n",
    "\n",
    "The Harris Corner Detector is primarily designed for detecting corner points or keypoints in images and not specifically meant for detecting edges. While it can potentially detect some edges, its primary focus is on identifying corners in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = np.float32(cv.cvtColor(img,cv.COLOR_BGR2GRAY))\n",
    "harris = cv.cornerHarris(gray,2,3,0.1)\n",
    "plt.figure(figsize=(10, 10)), plt.axis(\"off\"), plt.imshow(harris, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to normalize image?\n",
    "\n",
    "Normalize the image by dividing by 256, then subtracting the mean i.e. 0.5, and then amplifying the values by multiplying by 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image_norm=image/256.0\n",
    "    image_norm=image_norm-0.5\n",
    "    image_norm=image_norm*2\n",
    "    plot_images(image, image_norm)\n",
    "    return image_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_image = normalize(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to central crop image?\n",
    "\n",
    "Reduce the size of the image around the center.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_crop(image, crop_height, crop_width):\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    offset_height = (image_height - crop_height) // 2\n",
    "    offset_width = (image_width - crop_width) // 2\n",
    "    image_crop = image[offset_height:offset_height + crop_height, offset_width:\n",
    "                 offset_width + crop_width, :]\n",
    "    plot_images(image, image_crop)\n",
    "    return image_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = central_crop(img, 213, 320)\n",
    "print(\"Size of original image: \", img.shape)\n",
    "print(\"Size of cropped image: \", cropped_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to convert BGR image to RGB image?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGR2RGB(image):\n",
    "    B, G, R = cv.split(image)\n",
    "    processed_image = cv.merge([R, G, B])\n",
    "    plot_images(image, processed_image)\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_image = BGR2RGB(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to resize the shortest edge of an image?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_shortest_edge(image, size):\n",
    "    H, W = image.shape[:2]\n",
    "    if H >= W:\n",
    "        nW = size\n",
    "        nH = int(float(H)/W * size)\n",
    "    else:\n",
    "        nH = size\n",
    "        nW = int(float(W)/H * size)\n",
    "    processed_image = cv.resize(image,(nW,nH))\n",
    "    plot_images(image, processed_image)\n",
    "\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image = resize_shortest_edge(img, 200)\n",
    "print(\"Size of original image: \", img.shape)\n",
    "print(\"Size of processed image: \", processed_image.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
