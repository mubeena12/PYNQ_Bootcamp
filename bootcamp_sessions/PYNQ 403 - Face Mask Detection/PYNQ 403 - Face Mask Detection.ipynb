{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88e2d11",
   "metadata": {},
   "source": [
    "# Face-mask detection on KRIA\n",
    "\n",
    "**Decription:** Using a Convolutional Neural Network (CNN) detects if a person is wearing a face-mask or not. The following notebook can either run on an image or a feed from a webcam\n",
    "\n",
    "**Model:** yolo-fastest\n",
    "\n",
    "**Input:** 512 x 512 resolution images\n",
    "\n",
    "**Output:** Two tensors, one with bounding box coordinates, other with the confidence score of prediction\n",
    "\n",
    "\n",
    "## 1. Prepare the overlay\n",
    "Program the FPGA, on the KRIA board, with DPU (Deep Learning Processing Unit) Overlay file called *dpu.bit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181a7ff3",
   "metadata": {},
   "source": [
    "## 2. Import in-built libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import colorsys\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09620a21",
   "metadata": {},
   "source": [
    "## 3. Load the pre-trained model on the overlay programmed in step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"pt_face-mask-detection.xmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499834b",
   "metadata": {},
   "source": [
    "## 4. Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_list = [10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326]\n",
    "anchor_float = [float(x) for x in anchor_list]\n",
    "anchors = np.array(anchor_float).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d78f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get model classification information'''\t\n",
    "def get_class(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "    \n",
    "classes_path = \"data/face_mask_names.txt\" # give the path to  file containing classes: Mask and No Mask\n",
    "class_names = get_class(classes_path)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "#creating a colors list to store colors\n",
    "colors = list(map(lambda x: \n",
    "                  (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), \n",
    "                  colors))\n",
    "random.seed(0)\n",
    "random.shuffle(colors)\n",
    "random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a16b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''resize image with unchanged aspect ratio using padding'''\n",
    "def letterbox_image(image, size):\n",
    "    ih, iw, _ = image.shape\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    #print(scale)\n",
    "    \n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "    #print(nw)\n",
    "    #print(nh)\n",
    "\n",
    "    image = cv2.resize(image, (nw,nh), interpolation=cv2.INTER_LINEAR)\n",
    "    new_image = np.ones((h,w,3), np.uint8) * 128\n",
    "    h_start = (h-nh)//2\n",
    "    w_start = (w-nw)//2\n",
    "    new_image[h_start:h_start+nh, w_start:w_start+nw, :] = image\n",
    "    return new_image\n",
    "\n",
    "\n",
    "'''image preprocessing'''\n",
    "def pre_process(image, model_image_size):\n",
    "    image = image[...,::-1]\n",
    "    image_h, image_w, _ = image.shape\n",
    " \n",
    "    if model_image_size != (None, None):\n",
    "        assert model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "        assert model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "        boxed_image = letterbox_image(image, tuple(reversed(model_image_size)))\n",
    "    else:\n",
    "        new_image_size = (image_w - (image_w % 32), image_h - (image_h % 32))\n",
    "        boxed_image = letterbox_image(image, new_image_size)\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0) \t\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''boxes_and_score is calling correct_boxes and _get_feats function'''\n",
    "\n",
    "# function to get features\n",
    "def _get_feats(feats, anchors, num_classes, input_shape):\n",
    "    num_anchors = len(anchors)\n",
    "    anchors_tensor = np.reshape(np.array(anchors, dtype=np.float32), [1, 1, 1, num_anchors, 2])\n",
    "    grid_size = np.shape(feats)[1:3]\n",
    "    nu = num_classes + 5\n",
    "    predictions = np.reshape(feats, [-1, grid_size[0], grid_size[1], num_anchors, nu])\n",
    "    grid_y = np.tile(np.reshape(np.arange(grid_size[0]), [-1, 1, 1, 1]), [1, grid_size[1], 1, 1])\n",
    "    grid_x = np.tile(np.reshape(np.arange(grid_size[1]), [1, -1, 1, 1]), [grid_size[0], 1, 1, 1])\n",
    "    grid = np.concatenate([grid_x, grid_y], axis = -1)\n",
    "    grid = np.array(grid, dtype=np.float32)\n",
    "\n",
    "    box_xy = (1/(1+np.exp(-predictions[..., :2])) + grid) / np.array(grid_size[::-1], dtype=np.float32)\n",
    "    box_wh = np.exp(predictions[..., 2:4]) * anchors_tensor / np.array(input_shape[::-1], dtype=np.float32)\n",
    "    box_confidence = 1/(1+np.exp(-predictions[..., 4:5]))\n",
    "    box_class_probs = 1/(1+np.exp(-predictions[..., 5:]))\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "\n",
    "def correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = np.array(input_shape, dtype = np.float32)\n",
    "    image_shape = np.array(image_shape, dtype = np.float32)\n",
    "    new_shape = np.around(image_shape * np.min(input_shape / image_shape))\n",
    "    offset = (input_shape - new_shape) / 2. / input_shape\n",
    "    scale = input_shape / new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes = np.concatenate([\n",
    "        box_mins[..., 0:1],\n",
    "        box_mins[..., 1:2],\n",
    "        box_maxes[..., 0:1],\n",
    "        box_maxes[..., 1:2]\n",
    "    ], axis = -1)\n",
    "    boxes *= np.concatenate([image_shape, image_shape], axis = -1)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def boxes_and_scores(feats, anchors, classes_num, input_shape, image_shape):\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = _get_feats(feats, anchors, classes_num, input_shape)\n",
    "    boxes = correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = np.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = np.reshape(box_scores, [-1, classes_num])\n",
    "    return boxes, box_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_boxes(boxes, scores):\n",
    "    \"\"\"Suppress non-maximal boxes.\n",
    "\n",
    "    # Arguments\n",
    "        boxes: ndarray, boxes of objects.\n",
    "        scores: ndarray, scores of objects.\n",
    "\n",
    "    # Returns\n",
    "        keep: ndarray, index of effective boxes.\n",
    "    \"\"\"\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2-x1+1)*(y2-y1+1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w1 = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h1 = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w1 * h1\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        inds = np.where(ovr <= 0.55)[0]  # threshold\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "'''The following function returns the coordinates of the boxes, scores, and the class (mask or no mask). \n",
    "To do so it calls boxes_and_scores and nms_boxes function'''\n",
    "def evaluate(yolo_outputs, image_shape, class_names, anchors):\n",
    "    score_thresh = 0.2\n",
    "    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    input_shape = np.shape(yolo_outputs[0])[1 : 3]\n",
    "    input_shape = np.array(input_shape)*32\n",
    "\n",
    "    for i in range(len(yolo_outputs)):\n",
    "        _boxes, _box_scores = boxes_and_scores(\n",
    "            yolo_outputs[i], anchors[anchor_mask[i]], len(class_names), \n",
    "            input_shape, image_shape)\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = np.concatenate(boxes, axis = 0)\n",
    "    box_scores = np.concatenate(box_scores, axis = 0)\n",
    "\n",
    "    mask = box_scores >= score_thresh\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    for c in range(len(class_names)):\n",
    "        class_boxes_np = boxes[mask[:, c]]\n",
    "        class_box_scores_np = box_scores[:, c]\n",
    "        class_box_scores_np = class_box_scores_np[mask[:, c]]\n",
    "        nms_index_np = nms_boxes(class_boxes_np, class_box_scores_np) \n",
    "        class_boxes_np = class_boxes_np[nms_index_np]\n",
    "        class_box_scores_np = class_box_scores_np[nms_index_np]\n",
    "        classes_np = np.ones_like(class_box_scores_np, dtype = np.int32) * c\n",
    "        boxes_.append(class_boxes_np)\n",
    "        scores_.append(class_box_scores_np)\n",
    "        classes_.append(classes_np)\n",
    "    boxes_ = np.concatenate(boxes_, axis = 0)\n",
    "    scores_ = np.concatenate(scores_, axis = 0)\n",
    "    classes_ = np.concatenate(classes_, axis = 0)\n",
    "\n",
    "    return boxes_, scores_, classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Draw detection frame'''\n",
    "def draw_boxes(image, boxes, scores, classes):\n",
    "    _, ax = plt.subplots(1)\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    image_h, image_w, _ = image.shape\n",
    "\n",
    "    for i, bbox in enumerate(boxes):\n",
    "        [top, left, bottom, right] = bbox\n",
    "        width, height = right - left, bottom - top\n",
    "        center_x, center_y = left + width*0.5, top + height*0.5\n",
    "        x = int(center_x - width)\n",
    "        y = int(center_y - height)\n",
    "        w = int(width)\n",
    "        h = int(height)\n",
    "        score, class_index = scores[i], classes[i]\n",
    "        label = '{}: {:.4f}'.format(class_names[class_index], score) \n",
    "        color = tuple([color/255 for color in colors[class_index]])\n",
    "        ax.add_patch(Rectangle((left, top), width, height,\n",
    "                               edgecolor=color, facecolor='none'))\n",
    "        ax.annotate(label, (center_x, center_y), color=color, weight='bold', \n",
    "                    fontsize=12, ha='center', va='center')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929ad55",
   "metadata": {},
   "source": [
    "## Load the images for running mask detection\n",
    "\n",
    "These images will be used to test if the the face-mask detection model is able to detect the mask or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'img/' #path to the folder containing images\n",
    "original_images = [i for i in os.listdir(image_folder) if i.endswith(\"jpg\")] #put the images in original images list, if jpg\n",
    "total_images = len(original_images) #getting the length of original_images list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33548d91",
   "metadata": {},
   "source": [
    "## Start the overlay\n",
    "\n",
    "Follow these three steps to run the overlay, get the input tensors, and output tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e7c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3009c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeIn = tuple(inputTensors[0].dims) #get the shape of the input tensor\n",
    "print(shapeIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1411ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the shape of the output tensor\n",
    "#for this model we have two output tensors: \n",
    "#one containing the bounding box coordinates and second containing the confidence score\n",
    "shapeOut0 = (tuple(outputTensors[0].dims)) \n",
    "shapeOut1 = (tuple(outputTensors[1].dims)) \n",
    "print(shapeOut0)\n",
    "print(shapeOut1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputSize0 = int(outputTensors[0].get_data_size() / shapeIn[0]) # 12675\n",
    "outputSize1 = int(outputTensors[1].get_data_size() / shapeIn[0]) # 50700\n",
    "print(outputSize0)\n",
    "print(outputSize1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f758b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "output_data = [np.empty(shapeOut0, dtype=np.float32, order=\"C\"), \n",
    "               np.empty(shapeOut1, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544bb9e4",
   "metadata": {},
   "source": [
    "## Function to run mask detection on KRIA\n",
    "\n",
    "This is the top function that will call other utility functions to run face mask detection on KRIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d48628",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Run takes the image, and calls three functions pre_process, evaluate, and draw_boxes function'''\n",
    "def run(image_index, display=False):\n",
    "    # Read input image\n",
    "    input_image = cv2.imread(os.path.join(image_folder, original_images[image_index]))\n",
    "    print(input_image.shape)\n",
    "    # Pre-processing\n",
    "    image_size = input_image.shape[:2]\n",
    "    #Note here we are giving the input image size 512 x 512\n",
    "    image_data = np.array(pre_process(input_image, (512, 512)), dtype=np.float32) \n",
    "    \n",
    "    # Fetch data to DPU and trigger it\n",
    "    image[0,...] = image_data.reshape(shapeIn[1:])\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    \n",
    "    # Retrieve output data\n",
    "    conv_out0 = np.reshape(output_data[0], shapeOut0)\n",
    "    conv_out1 = np.reshape(output_data[1], shapeOut1)\n",
    "    yolo_outputs = [conv_out0, conv_out1]\n",
    "    \n",
    "    # Decode output from YOLOv3\n",
    "    boxes, scores, classes = evaluate(yolo_outputs, image_size, class_names, anchors)\n",
    "    \n",
    "    if display:\n",
    "        _ = draw_boxes(input_image, boxes, scores, classes)\n",
    "#     print(\"Number of detected objects: {}\".format(len(boxes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fae83d",
   "metadata": {},
   "source": [
    "## Make a function call to run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ada964",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(8, display=True) #change the image index from 1 to 8 to detect face mask on different images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14222699",
   "metadata": {},
   "source": [
    "## Setting up the webcam\n",
    "\n",
    "Use the following three steps to set up the webcam: \n",
    "1. Capture Video\n",
    "2. Set frame height\n",
    "3. Set frame width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, 640);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, 480);\n",
    "\n",
    "print(\"Capture device is open: \" + str(videoIn.isOpened()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e971c",
   "metadata": {},
   "source": [
    "## Read one frame (image) from the webcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = videoIn.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561dbf2e",
   "metadata": {},
   "source": [
    "## Function to run face mask detection on live webcam feed\n",
    "\n",
    "Similar to the run function we used above to detect face mask, we write another top function called run_webcam to run face mask detection on webcam feed. \n",
    "\n",
    "The only difference between run and run_webcam is the function called to draw bounding boxes on the face.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7026690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webcam(webcam_image, display=False):\n",
    "    # Read input image\n",
    "    input_image = webcam_image\n",
    "    # Pre-processing\n",
    "    image_size = input_image.shape[:2]\n",
    "    image_data = np.array(pre_process(input_image, (512, 512)), dtype=np.float32)\n",
    "    \n",
    "    # Fetch data to DPU and trigger it\n",
    "    image[0,...] = image_data.reshape(shapeIn[1:])\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    \n",
    "    # Retrieve output data\n",
    "    conv_out0 = np.reshape(output_data[0], shapeOut0)\n",
    "    conv_out1 = np.reshape(output_data[1], shapeOut1)\n",
    "    yolo_outputs = [conv_out0, conv_out1]\n",
    "    \n",
    "    # Decode output from YOLOv3\n",
    "    boxes, scores, classes = evaluate(yolo_outputs, image_size, class_names, anchors)\n",
    "    \n",
    "    if display:\n",
    "        input_image = draw_boxes_on_frame(input_image, boxes, scores, classes) #different function called to draw bouding boxes\n",
    "    return  input_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes_on_frame(image, boxes, scores, classes):\n",
    "    image_h, image_w, _ = image.shape\n",
    "    for i, bbox in enumerate(boxes):\n",
    "        [top, left, bottom, right] = bbox\n",
    "        width, height = right - left, bottom - top\n",
    "        center_x, center_y = left + width*0.5, top + height*0.5\n",
    "        x = int(center_x - width)\n",
    "        y = int(center_y - height)\n",
    "        w = int(width)\n",
    "        h = int(height)\n",
    "        cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n",
    "        score, class_index = scores[i], classes[i]\n",
    "        label = '{}: {:.4f}'.format(class_names[class_index], score)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        color = (255, 0, 0)\n",
    "        fontScale=1\n",
    "        thickness=2\n",
    "        image = cv2.putText(image, label, (int(center_x), int(center_y)), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d98695",
   "metadata": {},
   "source": [
    "## Code to display live webcam feed in the notebook\n",
    "\n",
    "The following piece of code displays the webcam feed in the jupyter notebook and continuously reads and sends the frames to run_webcam function for detecting mask.\n",
    "\n",
    "To stop the feed from webcam, click on the black square bottom in the toolbar. If you hover on the black square button, it will show 'Interrupt the kernel'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a319b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display_handle=display(None, display_id=True)\n",
    "try:\n",
    "    while True:\n",
    "        _, frame = videoIn.read()\n",
    "        frame = run_webcam(frame, display=True)\n",
    "#         frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    videoIn.release()\n",
    "    display_handle.update(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8a772",
   "metadata": {},
   "source": [
    "## Always run the below line of code to release the webcam device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoIn.release() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c7e62",
   "metadata": {},
   "source": [
    "## To get the performance of KRIA board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26aa6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "[run(i) for i in range(total_images)]\n",
    "time2 = time.time()\n",
    "fps = total_images/(time2-time1)\n",
    "print(\"Performance: {} FPS\".format(fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650172e6",
   "metadata": {},
   "source": [
    "## Always delete the overlay and dpu object deployed on KRIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781b102",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "1. Print total objects detected in the image/frame.\n",
    "2. Ring a siren when a person is detected without a face mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e528a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
